---
title: "Data  in dexter"
author: "Jesse Koops"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data in dexter}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style>
img{ border:none;}
</style>

```{r, message=FALSE}
library(dexter)
library(dplyr)
library(tidyr)
```


**Dexter** is intended as a fairly comprehensive system for managing and analyzing data from administrations of educational and psychological tests. Functions that perform an analysis in dexter all have an argument `dataSrc`. This argument is overloaded, which means it can have multiple formats. These are:

1. the traditional data.matrix where the columns are items and the rows are persons. Each cell contains a scored response and structural missing values are coded as NA. This format is typically expected by all IRT packages in R.

2. long format data with (at least) the columns: person_id, item_id, item_score. Each row reflects a single response by a particular person to a particular item. There are no NA values; if a person did not respond to an item there is just no row for that particular person-item combination

3. a dexter project database

Of these options, the first is the most well known but options 2 and 3 provide a lot more flexibility. Additionally, option 3 allows you to keep your data in a persistent, rich and well structured format which is very helpful if data comes in over a longer (time) period and generally makes working with - potentially high stakes - data both safer and easier.

We will illustrate this with the verbal aggression dataset. First, as a data.matrix

```{r,results='hide'}
dm.aggr = verbAggrData %>%
  select(-anger, -gender) %>%
  data.matrix()

f.dm = fit_enorm(dm.aggr)
```

Then in long format

```{r,results='hide'}
long.aggr = verbAggrData %>%
  mutate(person_id=row_number()) %>%
  gather(key='item_id', value='item_score', -gender, -anger, -person_id)

f.long = fit_enorm(long.aggr)
```

Finally, we use a project database

```{r,results='hide',message=FALSE}
db = start_new_project(verbAggrRules, ':memory:', 
                       person_properties = list(gender=character(), anger=integer()))

add_booklet(db, verbAggrData, booklet_id='vansteelandt')

f.db = fit_enorm(db)
```

It will surprise no one that the results in these cases are equal.

```{r}
identical(coef(f.dm), coef(f.long))
identical(coef(f.long), coef(f.db))
```

<!-- to do: is is possible to document classes, see DBIConnection -->

# Databases

According to wikipedia, a database is an organised collection of data. Not all R users are familiar with the use of databases. In R, as in most other languages, interaction with a databases is done via a _connection object_. The connection object provides access to the database, e.g. it can be used to read data from the database or send data to the database.

A database has to live somewhere, this depends on the type of databases and can be in memory, in a single file or many files in a single or multiple directories or even distributed across multiple computers. Wherever it lives, the connection object provides access to the data via a common interface, usually SQL<to do: link>. 

The database system used by dexter is _SQLite_ as can be seen when we print the connection object we created above. 

```{r}
db
```

SQLite stores it's databases in a single file, which is often convenient. A connection to the database can be established through the dexter functions `start_new_project`, which sets up the relevant database structure and creates a new database or `open_project` which opens an existing project. Both functions need the path to a database file. Note that when we started a new project above we used the string `':memory:'` instead of a proper path. This is a special name which creates an _in memory_ database, which is convenient to do in a vignette. <!-- to do: update error messages when people accidentally provide a string -->

If you use a database, which we wholeheartedly recommend, you have to provide that connection object to each functions in dexter that adds to, changes or reads data. For example, we provided the connection object (db) to the function `add_booklet` above, so that response data for the booklet (verbAggrData) could be added to the database.

```{r,eval=F}
add_booklet(db, verbAggrData, booklet_id='vansteelandt')
```


## Item & person properties

A database is a nice way to organize and store your data but there are other benefits. One is that you can easily enrich your data with person and item properties. Person properties can be added using the function `add_person_properties` or, together with response data, using the function `add_booklet`. If we look in the _verbAggrData_ example data set, we see that it contains two person properties, namely _gender_ and a score on a different questionnaire <!-- to do: update help for dataset -->, the anger <!-- to do: anger something --> scale. It is not unusual for data to come in this format, therefore add_booklet recognizes and imports any columns in the data it recognizes as person properties. Of course, it is necessary that dexter knows about  <!-- to do: why not specify the pp properties to add_booklet, more logical than in start_new_project --> these columns.

```{r,eval=F}
db = start_new_project(verbAggrRules, ':memory:', 
                       person_properties = list(gender=character(), anger=integer()))

add_booklet(db, verbAggrData, booklet_id='vansteelandt')
```

We can also add item properties for any item already known in the database (i.e. scoring rules must already be defined for these items). In this case we have item properties in _verbAggrProperties_

```{r}
head(verbAggrProperties)
```

We can add them as follows (note that the first argument is the _database connection object_):

```{r}
add_item_properties(db, verbAggrProperties)
```

With or data thus enriched, we can use the person and item properties in our analysis, for example in the profile plot:

```{r}
profile_plot(db, 'mode', 'gender')

```

Note that the profile_plot function knows how to use the item property _mode_ and the person property _gender_ from the database. More information about the use and interpretation of profile plots can be found in the vignette <to do: link>.

## Predicates

All data analysis functions accept an optional argument called `predicate` which is used for data selection. In this predicate you can use any variable defined in the project. This includes person and item properties and things dexter knows about by default. To see which variables are available, use:

```{r}
get_variables(db)

```




### A note about names

Due to the fact that we use an SQL database as a backend, the names of all item properties and person covariates must be valid SQL column names. This means that the name has to start with a letter and may contain only letters, numbers and underscores. Specifically, the dot {.} that is often used in variable names in R, cannot be used in a column name. Names that are not valid SQL column names will be silently converted. All names will also be converted to lowercase. 

Of course this only applies to column names, values have no such restrictions.




## Tidy data

All data in dexter is stored and treated as normalized data, which is often called tidy data in the R world. As a result dexter ties in nicely with the Tidyverse packages and it is easy to extract tidy data from dexter and use it in ggplot or for your own summaries and statistics. As an example we look at the distribution of responses for the items in the verbal aggression dataset.

```{r}

get_responses(db, columns = c('item_id','response')) %>%
  group_by(item_id, response) %>%
  summarise(count = n()) %>%
  slice(1:10)
  
```
It is also easy enough to make some plots based on one of the item properties (situation in this instance). For the verbal aggression dataset this makes sense since identical items were administered for all situations, which makes the scores for each situation directly comparable.


```{r, fig.height=5,fig.width=7}
scores = get_responses(db, columns = c('person_id','item_score','situation')) %>%
  group_by(person_id, situation) %>%
  summarise(situation_score = sum(item_score))  

par(bty='n', fg='white')

boxplot(situation_score ~ situation, scores, border='black')

```



## Selecting data

Dexter keeps all scoring rules separately from response data, and applies them just before analysis. Together with the powerful techniques for quality analysis, from classical test statistics over distractor plots to the interaction model, this should allow users to detect and correct any items that have a technical flaw, such as a wrong key, which can be corrected with the function `touch_rules()`.

Nevertheless, there are occasions when an item, a booklet or a person must be omitted from analysis. Dexter implements a general system for subsetting data that offers an immensely wider range of possibilities -- and some risks!

Many functions accept an optional argument `predicate`, which is an expression to subset data on. In this expression you can use item_properties, person covariates and several other variables to filter your data. To see which predicate variables are available in your project, use the function `get_variables`.

```{r}
get_variables(db)
```

As an example, suppose we know of a printing error in the third item in booklet "pretest" so we want to turn it off locally, and we also want to estimate the parameters solely for women. We can pass to `fit_enorm` the following predicate expression:

```{r, eval=FALSE}
par = fit_enorm(db, gender=='female' & !(booklet_id == 'pretest' & item_position == 3))
```

You can also use local variables in your expression, therefore the statement below is equivalent to the previous one:

```{r, eval=FALSE}
bkl = 'pretest'
par = fit_enorm(db, gender=='female' & !(booklet_id == bkl & item_position == 3))
```

However, if you have want to use local variables that conflict with the variable names in your dexter project, it is best to resolve the ambiguity by using the function `local()` around your local variables:

```{r, eval=FALSE}
booklet_id = 'pretest' # local variable
par = fit_enorm(db, gender=='female' & !(booklet_id == local(booklet_id) & item_position == 3))
```

For consistency, predicates also work when the `dataSrc` argument is a data.frame.

Because the `predicate` is passed to the functions that use it independently, one can do strange things like estimate an IRT model from the test responses of females, and use it to score the tests of males. 

Another risk with subsetting is that it may destroy the connectedness of the design. The user can check against this with the function `design_info` (which also offers other useful information about the design).

```{r, eval=FALSE}
# assuming an item property called `cefr_level` exists in the project
design = design_info(db, booklet_id %in% c('bookletA','bookletX','bookletY') & cefr_level == 'B1')
design$connected
## [1] TRUE
```



Even though predicates offer a lot of flexibility, there are some limitations due to the fact that they only work on the individual response level. The typical case that can not be solved by using a predicate, is to omit a whole booklet or person based on some of their responses, but fortunately there is a relatively easy way to get around that limitation. 

The following example assumes there are some missing values in your data. Remember, Dexter converts all responses to strings and treats `NA` responses as the string `'NA'`. The following line will omit the missing responses (rather than scoring them 0), and calibrate the extended nominal response model. Based on this predicate, only individual missing responses will be omitted, which does not extend to exclusion of whole persons.

```{r, eval=FALSE}
par = fit_enorm(db, response != 'NA')
```

But there might be a valid consideration for wanting to omit all persons who had *any* missing responses, perhaps administration conditions that caused the missing responses were distracting enough to influence other answers. While this is not possible using just the predicate mechanism, Dexter supports extracting the data, manipulating it and feeding it back to an analysis function manually. The following example will use dplyr to do this in a concise way.

```{r, eval=FALSE}
# goal: fit the extended nominal response model using only persons without any missing responses

data = get_responses(db, columns=c('person_id','item_id','item_score','response')) %>%
    group_by(person_id) %>%
    mutate(any_missing = any(response == 'NA')) %>%
    ungroup() %>%
    filter(!any_missing)

# the manipulated data can be fed back to the analysis function
par = fit_enorm(data)
```





```{r, include=FALSE}
close_project(db)
```